{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.transforms import functional as FN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from time import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotholeDataset(Dataset):\n",
    "    def __init__(self, json_file, transform=None, target_transform=None, subset=None):\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.subset = subset\n",
    "        self.cropped_data = []\n",
    "        self.prepare_dataset()\n",
    "\n",
    "        self.augment_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(20),  # Rotate by Â±20 degrees\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            self.random_noise\n",
    "        ])\n",
    "\n",
    "    def random_noise(self, img):\n",
    "        if random.random() < 0.5:  # 50% chance to add noise\n",
    "            noise = torch.randn(img.size()) * 0.05\n",
    "            img = img + noise\n",
    "            img = torch.clamp(img, 0, 1)\n",
    "        return img\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        for item in self.data:\n",
    "            if self.subset is not None and item.get('subset') != self.subset:\n",
    "                continue\n",
    "            image_path = item['image']\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            for box_info in item['boxes']:\n",
    "                box = box_info['box']\n",
    "                label = box_info['label']\n",
    "                cropped_image = FN.crop(image, box[1], box[0], box[3], box[2])  # top, left, height, width\n",
    "                if self.transform:\n",
    "                    cropped_image = self.transform(cropped_image)\n",
    "                self.cropped_data.append((cropped_image, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cropped_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.cropped_data[idx]\n",
    "\n",
    "\n",
    "        # Check if the label is positive (1), and apply augmentations if so\n",
    "        if label == 1:\n",
    "            image = self.augment_transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative class samples count: 784911\n",
      "Positive class samples count: 18974\n"
     ]
    }
   ],
   "source": [
    "with open('processed_images_data_ss.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "count_negative_class_samples = 0\n",
    "count_positive_class_samples = 0\n",
    "\n",
    "# Iterate through the data and count the labels\n",
    "for entry in data:\n",
    "    for box in entry['boxes']:\n",
    "        if box['label'] == 0:\n",
    "            count_negative_class_samples += 1\n",
    "        elif box['label'] == 1:\n",
    "            count_positive_class_samples += 1\n",
    "\n",
    "print(\"Negative class samples count:\", count_negative_class_samples)\n",
    "print(\"Positive class samples count:\", count_positive_class_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the cropped images\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = PotholeDataset(json_file='processed_images_data_ss.json', transform=transform, subset='train')\n",
    "\n",
    "# Separate indices for negative and positive class samples\n",
    "negative_indices = [i for i, (_, label) in enumerate(train_dataset) if label == 0]\n",
    "positive_indices = [i for i, (_, label) in enumerate(train_dataset) if label == 1]\n",
    "\n",
    "# Randomly downsample negative class\n",
    "random.shuffle(negative_indices)\n",
    "downsampled_negative_indices = negative_indices[:len(positive_indices)]\n",
    "\n",
    "# Combine positive and downsampled negative indices\n",
    "balanced_indices = downsampled_negative_indices + positive_indices\n",
    "random.shuffle(balanced_indices)  # Shuffle to mix positive and negative samples\n",
    "\n",
    "# Create a subset of the dataset using the balanced indices\n",
    "balanced_train_dataset = Subset(train_dataset, balanced_indices)\n",
    "\n",
    "# DataLoader using the balanced dataset\n",
    "train_loader = DataLoader(balanced_train_dataset, batch_size=4, shuffle=True, num_workers=3)\n",
    "\n",
    "test_dataset = PotholeDataset(json_file='processed_images_data_ss.json', transform=transform, subset='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b775f33944ae448cb69d0e39398bd74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels equal to 1: 80\n",
      "Number of labels equal to 0: 6180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(test_loader))\n",
    "print (len(images))\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "count = 0\n",
    "count_b = 0\n",
    "# Assuming 'labels' is a tensor containing the labels for the images\n",
    "for minibatch_no, (data, target) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "    \n",
    "# Count the number of labels that are equal to 1\n",
    "    count += (target == 1).sum().item()\n",
    "    count_b += (target == 0).sum().item()\n",
    "# Printing the count\n",
    "print(\"Number of labels equal to 1:\", count)\n",
    "print(\"Number of labels equal to 0:\", count_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c061a0ca98467d8815f7338aa1b0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels equal to 1: 583\n",
      "Number of labels equal to 0: 583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print (len(images))\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "count = 0\n",
    "count_b = 0\n",
    "# Assuming 'labels' is a tensor containing the labels for the images\n",
    "for minibatch_no, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "    \n",
    "# Count the number of labels that are equal to 1\n",
    "    count += (target == 1).sum().item()\n",
    "    count_b += (target == 0).sum().item()\n",
    "# Printing the count\n",
    "print(\"Number of labels equal to 1:\", count)\n",
    "print(\"Number of labels equal to 0:\", count_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define the training as a function so we can easily re-use it.\n",
    "def train(model, optimizer, num_epochs):\n",
    "    out_dict = {'train_acc': [],\n",
    "              'test_acc': [],\n",
    "              'train_loss': [],\n",
    "              'test_loss': []}\n",
    "  \n",
    "    for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "        model.train()\n",
    "        #For each epoch\n",
    "        train_correct = 0\n",
    "        train_loss = []\n",
    "        for minibatch_no, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            #Zero the gradients computed for each weight\n",
    "            optimizer.zero_grad()\n",
    "            #Forward pass your image through the network\n",
    "            output = model(data)\n",
    "            #Compute the loss\n",
    "            loss = nn.CrossEntropyLoss()(output, target)\n",
    "            #Backward pass through the network\n",
    "            loss.backward()\n",
    "            #Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            #Compute how many were correctly classified\n",
    "            predicted = output.argmax(1)\n",
    "            train_correct += (target==predicted).sum().cpu().item()\n",
    "        #Comput the test accuracy\n",
    "        test_loss = []\n",
    "        test_correct = 0\n",
    "        model.eval()\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "            test_loss.append(nn.CrossEntropyLoss()(output, target).cpu().item())\n",
    "            predicted = output.argmax(1)\n",
    "            test_correct += (target==predicted).sum().cpu().item()\n",
    "        out_dict['train_acc'].append(train_correct/len(balanced_train_dataset ))\n",
    "        out_dict['test_acc'].append(test_correct/len(test_dataset))\n",
    "        out_dict['train_loss'].append(np.mean(train_loss))\n",
    "        out_dict['test_loss'].append(np.mean(test_loss))\n",
    "        print(f\"Loss train: {np.mean(train_loss):.3f}\\t test: {np.mean(test_loss):.3f}\\t\",\n",
    "              f\"Accuracy train: {out_dict['train_acc'][-1]*100:.1f}%\\t test: {out_dict['test_acc'][-1]*100:.1f}%\")\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet50()\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_adam = torch.optim.Adam(model_ft.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a89e18853e48cbb9e8b3b2e3999704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12fdd94630d44595b98b36e17d6bb4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.439\t test: 0.058\t Accuracy train: 79.1%\t test: 98.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8652bf1c2248c88f9a4a70a81d332b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.213\t test: 0.032\t Accuracy train: 93.9%\t test: 99.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf1853feb6b476e9875325b64270b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.111\t test: 0.034\t Accuracy train: 96.9%\t test: 99.5%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706854c0618e4293b290b89bed244e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.108\t test: 0.130\t Accuracy train: 97.2%\t test: 95.2%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06b85c592a24fb5b06c9efead86dea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train: 0.092\t test: 0.218\t Accuracy train: 97.8%\t test: 96.1%\n"
     ]
    }
   ],
   "source": [
    "out_dict = train(model_ft, optimizer_adam, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(),\"whatever.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

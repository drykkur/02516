{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "\n",
    "# pip install torchsummary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from time import time\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import selectivesearch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import clear_output\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection over Union: 0.14678899082568808\n"
     ]
    }
   ],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    # Convert (x_min, y_min, width, height) to (x_min, y_min, x_max, y_max)\n",
    "    box1_x_min, box1_y_min, box1_x_max, box1_y_max = box1\n",
    "\n",
    "    box2_x_min, box2_y_min, box2_width, box2_height = box2\n",
    "    box2_x_max = box2_x_min + box2_width\n",
    "    box2_y_max = box2_y_min + box2_height\n",
    "\n",
    "    # Calculate intersection coordinates\n",
    "    inter_x_min = max(box1_x_min, box2_x_min)\n",
    "    inter_y_min = max(box1_y_min, box2_y_min)\n",
    "    inter_x_max = min(box1_x_max, box2_x_max)\n",
    "    inter_y_max = min(box1_y_max, box2_y_max)\n",
    "\n",
    "    # Calculate intersection area\n",
    "    inter_width = max(0, inter_x_max - inter_x_min)\n",
    "    inter_height = max(0, inter_y_max - inter_y_min)\n",
    "    intersection_area = inter_width * inter_height\n",
    "\n",
    "    # Calculate union area\n",
    "    box1_area = (box1_x_max - box1_x_min) * (box1_y_max - box1_y_min)\n",
    "    box2_area = box2_width * box2_height\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    # Compute the IoU\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "# Example bounding boxes\n",
    "box1 = [50, 50, 100, 100]  # [x_min, y_min, width, height]\n",
    "box2 = [60, 60, 100, 100]\n",
    "\n",
    "iou = calculate_iou(box1, box2)\n",
    "print(f\"Intersection over Union: {iou}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/c9/4/202487/env2/lib/python3.10/site-packages/skimage/feature/texture.py:353: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 49\u001b[0m\n\u001b[1;32m     33\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(image, (x, y), (w, h), (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Display the image with bounding boxes\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#plt.imshow(image)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#plt.show()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#plt.imshow(resized_image)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#plt.show()\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m img_lbl, regions \u001b[38;5;241m=\u001b[39m \u001b[43mselectivesearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselective_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Initialize an empty set to store selected region proposals\u001b[39;00m\n\u001b[1;32m     53\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/env2/lib/python3.10/site-packages/selectivesearch/selectivesearch.py:272\u001b[0m, in \u001b[0;36mselective_search\u001b[0;34m(im_orig, scale, sigma, min_size)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, {}\n\u001b[1;32m    271\u001b[0m imsize \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 272\u001b[0m R \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_regions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# extract neighbouring information\u001b[39;00m\n\u001b[1;32m    275\u001b[0m neighbours \u001b[38;5;241m=\u001b[39m _extract_neighbours(R)\n",
      "File \u001b[0;32m~/env2/lib/python3.10/site-packages/selectivesearch/selectivesearch.py:183\u001b[0m, in \u001b[0;36m_extract_regions\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m R\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    180\u001b[0m \n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# colour histogram\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     masked_pixels \u001b[38;5;241m=\u001b[39m hsv[:, :, :][img[:, :, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m==\u001b[39m k]\n\u001b[0;32m--> 183\u001b[0m     R[k][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmasked_pixels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     R[k][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhist_c\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _calc_colour_hist(masked_pixels)\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# texture histogram\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_path = \"Potholes/\"\n",
    "\n",
    "f_splits = open(os.path.join(data_path, \"splits.json\"))\n",
    "data_splits = json.load(f_splits)\n",
    "train_split = data_splits[\"train\"]\n",
    "test_split = data_splits[\"test\"]\n",
    "\n",
    "i = 0\n",
    "image_dict = {}\n",
    "for filename in train_split:\n",
    "\n",
    "\n",
    "    filename = os.path.join(data_path, \"annotated-images/\", filename)\n",
    "    \n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    boxes_list = []\n",
    "\n",
    "    for boxes in root.iter('object'):\n",
    "        ymin, xmin, ymax, xmax = None, None, None, None\n",
    "\n",
    "        ymin = int(boxes.find(\"bndbox/ymin\").text)\n",
    "        xmin = int(boxes.find(\"bndbox/xmin\").text)\n",
    "        ymax = int(boxes.find(\"bndbox/ymax\").text)\n",
    "        xmax = int(boxes.find(\"bndbox/xmax\").text)\n",
    "\n",
    "        boxes_list.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "    jpg_filename = filename.replace(\"xml\", \"jpg\")\n",
    "    image = cv2.imread(jpg_filename)\n",
    "\n",
    "    for (x, y, w, h) in boxes_list:\n",
    "        cv2.rectangle(image, (x, y), (w, h), (255, 0, 0), 2)\n",
    "    \n",
    "    # Display the image with bounding boxes\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n",
    "\n",
    "    #new_height = int(image.shape[1] / 4)\n",
    "    # Calculate a new width\n",
    "    #new_width = int(image.shape[0] / 2)\n",
    "    # Resize the image to the new dimensions\n",
    "    #resized_image = cv2.resize(image, (new_width, new_height))\n",
    "    \n",
    "    # Display the resized image using Matplotlib\n",
    "    #plt.imshow(resized_image)\n",
    "    #plt.show()\n",
    "\n",
    "    img_lbl, regions = selectivesearch.selective_search(\n",
    "    image)\n",
    "\n",
    "    # Initialize an empty set to store selected region proposals\n",
    "    candidates = set()\n",
    "    \n",
    "    output_image = image.copy()\n",
    "\n",
    "    j = 0\n",
    "    for bbox in boxes_list:\n",
    "        for region in regions:\n",
    "            box2 = region['rect']\n",
    "            iou = calculate_iou(bbox, box2)\n",
    "\n",
    "            if iou > 0.7:\n",
    "                (x, y, w, h) = region['rect']\n",
    "                \n",
    "\n",
    "                if image_dict.get(jpg_filename) is None:\n",
    "                    image_dict[jpg_filename] = [np.array([x,y,w,h,1])]\n",
    "                else:\n",
    "                    image_dict[jpg_filename].append(np.array([x,y,w,h,1]))\n",
    "                #cv2.rectangle(output_image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "            elif iou < 0.3:\n",
    "                if image_dict.get(jpg_filename) is None:\n",
    "                    image_dict[jpg_filename] = [np.array([x,y,w,h,0])]\n",
    "                else:\n",
    "                    image_dict[jpg_filename].append(np.array([x,y,w,h,0]))\n",
    "            \n",
    "    #plt.imshow(output_image)\n",
    "    #plt.show()\n",
    "with open(\"regions.pkl\", \"wb\") as file_save:\n",
    "    pickle.dump(image_dict, file_save)\n",
    "\n",
    "\n",
    "    \"\"\"for region in regions:\n",
    "        (x, y, w, h) = region['rect']\n",
    "        cv2.rectangle(output_image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Display the result  \n",
    "    plt.imshow(output_image)\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
